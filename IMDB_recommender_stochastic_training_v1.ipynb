{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n",
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import dgl\n",
    "import dgl.function as FN\n",
    "# import stanfordnlp\n",
    "import tqdm\n",
    "import re\n",
    "import string\n",
    "import tqdm\n",
    "import spotlight\n",
    "import pickle\n",
    "import time \n",
    "\n",
    "# Load Pytorch as backend\n",
    "dgl.load_backend('pytorch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DataSource:\n",
    "    CASSANDRA = \"cassandra\"\n",
    "    S3 = \"s3\"\n",
    "    JSON = \"json\"\n",
    "    LOCAL = \"local\"\n",
    "\n",
    "   \n",
    "# DO NOT EDIT\n",
    "# Exception Classes\n",
    "\n",
    "class PZAIException(Exception):\n",
    "    \"\"\"\n",
    "    Base class for other exceptions.\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "class DataSourceNotDefinedError(PZAIException):\n",
    "    \"\"\"\n",
    "    Raised when a particular data source is not defined for data import or export.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "class PortInformationNotFoundError(PZAIException):\n",
    "    \"\"\"\n",
    "    Raised when port details are not found for the particular port.\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "class UnknownOperationMode(PZAIException):\n",
    "    \"\"\"\n",
    "    Raised when a method or feature is not defined.\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "# DO NOT EDIT\n",
    "# Connection Manager Class\n",
    "\n",
    "class ConnectionManager:\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    @staticmethod\n",
    "    def get_data_for_a_port(data, port_number, connection_type):\n",
    "        \"\"\"\n",
    "        This method helps to get the details for one particular port information\n",
    "        :param data:\n",
    "        :param port_number:\n",
    "        :param connection_type:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        for each_data in data:\n",
    "            if int(each_data[\"port\"]) == int(port_number):\n",
    "                return each_data[\"sourceDetails\"]\n",
    "        raise PortInformationNotFoundError(\n",
    "            \"Port details not found for port_number {} in the {} connection\".format(port_number, connection_type))\n",
    "       \n",
    "    \n",
    "    \n",
    "def create_cassandra_table_if_not_exists(df, keypace, table_name, pk):\n",
    "    cassandra_keyspace = keypace\n",
    "    cassandra_table = table_name\n",
    "    schema_string = get_schema_string(df, pk)\n",
    "\n",
    "    query_cassandra_create_table = \"\"\"\n",
    "    CREATE TABLE {keyspace}.{table}({schema_string});\n",
    "    \"\"\".format(keyspace=cassandra_keyspace, table=cassandra_table, schema_string=schema_string)\n",
    "\n",
    "    print(query_cassandra_create_table)\n",
    "    drop_query = \"DROP TABLE IF EXISTS {keyspace}.{table}\".format(keyspace=cassandra_keyspace,table=cassandra_table)\n",
    "    session.execute(drop_query)\n",
    "    session.execute(query_cassandra_create_table)\n",
    "\n",
    "def get_schema_string(df, primary_k):\n",
    "    datatype_changer_dict = {\n",
    "        \"StringType\": \"text\",\n",
    "        \"IntegerType\": \"int\",\n",
    "        \"DateType\": \"int\",\n",
    "        \"LongType\": \"int\",\n",
    "        \"DoubleType\": \"double\"\n",
    "    }\n",
    "    columns = df.limit(2).toPandas().columns\n",
    "    schema_string = []\n",
    "    for each_column in columns:\n",
    "        data_type = str(list(df[[each_column]].schema)[0]).split(\",\")[1]\n",
    "        try:\n",
    "            data_type = datatype_changer_dict[data_type]\n",
    "        except:\n",
    "            data_type = None\n",
    "        schema_string.append(\"{column_name} {data_type}\".format(column_name=each_column, data_type=data_type))\n",
    "    schema_string.append(\"PRIMARY KEY ({})\".format(primary_k))\n",
    "    schema_string = \",\".join(schema_string)\n",
    "    return schema_string\n",
    "# DO NOT EDIT\n",
    "# Dataframe Connector\n",
    "\n",
    "class DataFrame(object):\n",
    "    \"\"\"\n",
    "    class that gets a data-frame from the mentioned port of the input-data\n",
    "    \"\"\"\n",
    "\n",
    "    def get(self, input_data, port_number):\n",
    "        \"\"\"\n",
    "        The function that gets the entire input configuration for the data and returns the selected data-frame.\n",
    "        :param input_data: list of dictionary for input configuration.\n",
    "        :param port_number: the port number from where the data has to be fetched.\n",
    "        :return: spark data-frame\n",
    "        \"\"\"\n",
    "        return self._get_df(input_data=input_data, port_number=port_number)\n",
    "\n",
    "    def _get_df(self, input_data, port_number):\n",
    "        \"\"\"\n",
    "        The function that gets the entire input configuration for the data and returns the selected data-frame.\n",
    "        :param input_data: list od dictionary for input configuration.\n",
    "        :param port_number: the port number from where the data has to be fetched.\n",
    "        :return: spark data-frame\n",
    "        \"\"\"\n",
    "        port_information = ConnectionManager.get_data_for_a_port(data=input_data,\n",
    "                                                                 port_number=port_number,\n",
    "                                                                 connection_type=\"input\")\n",
    "        data_source = str(port_information[\"source\"]).lower()\n",
    "        if data_source == DataSource.CASSANDRA:\n",
    "            df = self._get_df_from_cassandra(port_information)\n",
    "        elif data_source == DataSource.S3:\n",
    "            df = self._get_df_from_s3(port_information)\n",
    "        elif data_source==DataSource.LOCAL:\n",
    "            df=self._get_df_from_local(port_information)\n",
    "        else:\n",
    "            raise DataSourceNotDefinedError(\"Data-frame import from {} is currently not supported.\".format(data_source))\n",
    "        return df\n",
    "\n",
    "    def write(self, df, output_data, port_number):\n",
    "        \"\"\"\n",
    "        The function that gets the entire input configuration for the data and returns the selected data-frame.\n",
    "        :param df: The spark data-frame to be written out.\n",
    "        :param output_data: list of dictionary for output configuration.\n",
    "        :param port_number: the port number to which the data has to be written.\n",
    "        :return: boolean status\n",
    "        \"\"\"\n",
    "        return self.__write(df=df, output_data=output_data, port_number=port_number)\n",
    "\n",
    "    def __write(self, df, output_data, port_number):\n",
    "        \"\"\"\n",
    "        The function that gets the entire input configuration for the data and returns the selected data-frame.\n",
    "        :param df: The spark data-frame to be written out.\n",
    "        :param output_data: list of dictionary for output configuration.\n",
    "        :param port_number: the port number to which the data has to be written.\n",
    "        :return: boolean status\n",
    "        \"\"\"\n",
    "        port_information = ConnectionManager.get_data_for_a_port(data=output_data,\n",
    "                                                                 port_number=port_number,\n",
    "                                                                 connection_type=\"output\")\n",
    "        data_source = str(port_information[\"source\"]).lower()\n",
    "\n",
    "        if data_source == DataSource.CASSANDRA:\n",
    "            flag = self.__write_to_cassandra(df=df, source_information=port_information)\n",
    "        elif data_source == DataSource.S3:\n",
    "            flag = self.__write_to_s3(df=df, source_information=port_information)\n",
    "        else:\n",
    "            raise DataSourceNotDefinedError(\"Data-frame export to {} is currently not supported.\".format(data_source))\n",
    "        return flag\n",
    "\n",
    "    @staticmethod\n",
    "    def __write_to_cassandra(df, source_information):\n",
    "        \"\"\"\n",
    "        The function to write data to a cassandra table.\n",
    "        :param df:\n",
    "        :param source_information:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        table_name = source_information[\"tableName\"]\n",
    "        keyspace_name = source_information[\"keyspace\"]\n",
    "        write_mode = str(source_information[\"writeMode\"]).lower()\n",
    "        pk = str(source_information[\"primaryKeys\"]).lower()\n",
    "\n",
    "        for col in df.columns:\n",
    "            df = df.withColumnRenamed(col, col.lower())\n",
    "\n",
    "        if write_mode == \"append\":\n",
    "            df.write.format(\"org.apache.spark.sql.cassandra\").mode(write_mode).options(table=table_name,\n",
    "                                                                                       keyspace=keyspace_name).save()\n",
    "        elif write_mode == \"overwrite\":\n",
    "            create_cassandra_table_if_not_exists(df, keyspace_name, table_name, pk)\n",
    "            df.write.format(\"org.apache.spark.sql.cassandra\").mode(\"overwrite\").options(table=table_name,keyspace=keyspace_name).option(\"confirm.truncate\", \"true\").save()\n",
    "\n",
    "        else:\n",
    "            raise UnknownOperationMode(\"The mentioned writing mode {} is not defined for Cassandra.\".format(write_mode))\n",
    "        return True\n",
    "\n",
    "    @staticmethod\n",
    "    def __write_to_s3(df, source_information):\n",
    "        file_path = source_information[\"filePath\"]\n",
    "        file_format = source_information[\"fileFormat\"]\n",
    "        df.write.format(file_format).options(header='true').mode(\"overwrite\").save(file_path)        \n",
    "        return True\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_df_from_cassandra(source_information):\n",
    "        \"\"\"\n",
    "        The function to get data-frame from a cassandra table.\n",
    "        :param source_information:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        table_name = source_information[\"tableName\"]\n",
    "        keyspace_name = source_information[\"keyspace\"]\n",
    "        df = spark.read.format('org.apache.spark.sql.cassandra').options(table=table_name,\n",
    "                                                                         keyspace=keyspace_name).load()\n",
    "        return df\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_df_from_s3(source_information):\n",
    "        \"\"\"\n",
    "        The function to get data-frame from Amazon S3.\n",
    "        :param source_information:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        file_format = source_information[\"fileFormat\"]\n",
    "        file_path = source_information[\"filePath\"]\n",
    "        df = spark.read.format(file_format).options(header='true', inferSchema='true').load(file_path)\n",
    "        return df\n",
    "    @staticmethod\n",
    "    def _get_df_from_local(source_information):\n",
    "\n",
    "        df=pd.DataFrame()\n",
    "        file_format = source_information[\"fileFormat\"]\n",
    "        file_path = source_information[\"filePath\"]\n",
    "        try:\n",
    "            for filename in os.listdir(file_path):\n",
    "                if filename.endswith(file_format):\n",
    "                    if file_format==\"csv\":\n",
    "                        df1=pd.read_csv(file_path+\"/\"+filename)\n",
    "                        df=pd.concat([df,df1])\n",
    "                    elif file_format==\"parquet\":\n",
    "                        df1=pd.read_parquet(file_path+\"/\"+filename,engine=\"pyarrow\")\n",
    "                        df=pd.concat([df,df1])\n",
    "        except:\n",
    "            if file_format==\"csv\":\n",
    "                df=pd.read_csv(file_path)\n",
    "\n",
    "            elif file_format==\"parquet\":\n",
    "                df=pd.read_parquet(file_path,engine=\"pyarrow\")\n",
    "\n",
    "\n",
    "        return df\n",
    "\n",
    "\n",
    "\n",
    "request_data ={\n",
    "  \"input\": [\n",
    "    {\n",
    "      \"port\": 1,\n",
    "      \"dataType\": \"dataframe\",\n",
    "      \"sourceDetails\": {\n",
    "        \"source\": \"local\",\n",
    "        \"fileFormat\": \"csv\",\n",
    "        \"filePath\":r\"C:\\Users\\pv23228\\Documents\\P.AI\\Data\\Movies Dataset\\final_transactions_ss_trainset_v1.csv\"\n",
    "    }\n",
    "    },\n",
    "      {\n",
    "      \"port\": 2,\n",
    "      \"dataType\": \"dataframe\",\n",
    "      \"sourceDetails\": {\n",
    "        \"source\": \"local\",\n",
    "        \"fileFormat\": \"csv\",\n",
    "        \"filePath\": r\"C:\\Users\\pv23228\\Documents\\P.AI\\Data\\Movies Dataset\\final_item_data_ss_trainset_v1.csv\"\n",
    "      }\n",
    "    }, \n",
    "      {\n",
    "      \"port\": 3,\n",
    "      \"dataType\": \"dataframe\",\n",
    "      \"sourceDetails\": {\n",
    "        \"source\": \"local\",\n",
    "        \"fileFormat\": \"csv\",\n",
    "        \"filePath\": r\"C:\\Users\\pv23228\\Documents\\P.AI\\Data\\Movies Dataset\\final_customer_demographics_ss_trainset_v1.csv\"\n",
    "      }\n",
    "    }    \n",
    "  ],\n",
    "  \"output\": [\n",
    "    {\n",
    "      \"port\": 5,\n",
    "      \"dataType\": \"dataframe\",\n",
    "      \"sourceDetails\": {\n",
    "        \"source\": \"s3\",\n",
    "        \"fileFormat\": \"csv\",\n",
    "        \"filePath\": \"s3://zs-ds-pzai-general/data/customer_embeddings_imdb_tr_full_v1.csv\"\n",
    "      }\n",
    "    },\n",
    "      {\n",
    "      \"port\": 6,\n",
    "      \"dataType\": \"dataframe\",\n",
    "      \"sourceDetails\": {\n",
    "        \"source\": \"s3\",\n",
    "        \"fileFormat\": \"csv\",\n",
    "        \"filePath\": \"s3://zs-ds-pzai-general/data/item_embeddings_imdb_tr_full_v1.csv\"\n",
    "      }\n",
    "    },\n",
    "      {\n",
    "      \"port\": 7,\n",
    "      \"dataType\": \"dataframe\",\n",
    "      \"sourceDetails\": {\n",
    "        \"source\": \"s3\",\n",
    "        \"fileFormat\": \"csv\",\n",
    "        \"filePath\": \"s3://zs-ds-pzai-general/data/link_embeddings_imdb_tr_full_v1.csv\"\n",
    "      }\n",
    "    }\n",
    "  ],\n",
    "  \"function\": {\n",
    "    \"component\": \"objective\",\n",
    "    \"args\": {\n",
    "        \"features_for_item_node\":[],\n",
    "        \"features_for_customer_node\":[],\n",
    "        \"batch_size\": 2000,\n",
    "        \"epochs\": 4,\n",
    "        \"layer_size_of_hidden_layer\":[32],\n",
    "        \"number_of_neighbours_access\":[4]\n",
    "    }\n",
    "  },\n",
    "  \"meta\": {\n",
    "    \"triggeredBy\": \"Aditya Kothari\",\n",
    "    \"triggerTime\": \"2020-02-06 12:55:04\",\n",
    "    \"pipelineId\": \"pzai_pipeline_001\"\n",
    "  }\n",
    "}\n",
    "\n",
    "# DO NOT  EDIT BELOW\n",
    "input_data = request_data[\"input\"]\n",
    "output_data = request_data[\"output\"]\n",
    "arguments = request_data[\"function\"][\"args\"]\n",
    "meta_data = request_data[\"meta\"]\n",
    "\n",
    "\n",
    "transactions = DataFrame().get(input_data,1)\n",
    "items = DataFrame().get(input_data,2)\n",
    "customers = DataFrame().get(input_data,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(365521, 5)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transactions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(365170, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transactions = transactions.drop_duplicates()\n",
    "transactions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10363, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Adding a column to Customer Df as there are no features for users in IMDB\n",
    "customers[\"alive\"] = 1\n",
    "#coverting dtype for live column to category to experiment on building tensor for category type feature\n",
    "customers[\"alive\"] = customers[\"alive\"].astype('category')\n",
    "customers = customers.drop_duplicates()\n",
    "customers.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4799, 9)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items = items.drop_duplicates()\n",
    "items.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Storing user and product ids as a list, creating dict\n",
    "user_ids = list(customers.customer_id)\n",
    "product_ids = list(items.item_id)\n",
    "user_ids_invmap = {id_: i for i, id_ in enumerate(user_ids)}\n",
    "product_ids_invmap = {id_: i for i, id_ in enumerate(product_ids)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pv23228\\Anaconda3\\envs\\pai_dglv5_item\\lib\\site-packages\\dgl\\base.py:45: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.\n",
      "  return warnings.warn(message, category=category, stacklevel=1)\n",
      "C:\\Users\\pv23228\\Anaconda3\\envs\\pai_dglv5_item\\lib\\site-packages\\dgl\\base.py:45: DGLWarning: Keyword arguments ['multigraph'] are deprecated in v0.5, and can be safely removed in all cases.\n",
      "  return warnings.warn(message, category=category, stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "#Creating Graph\n",
    "g= dgl.DGLGraph(multigraph=True)\n",
    "g.add_nodes(len(user_ids) + len(product_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user features\n",
    "user_column =customers.columns[1]\n",
    "udata = torch.zeros(g.number_of_nodes(), dtype=torch.int64)\n",
    "# 0 for padding\n",
    "udata[:len(user_ids)] = torch.LongTensor(customers[user_column].cat.codes.values.astype('int64') + 1)\n",
    "g.ndata[user_column] = udata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ITEM features\n",
    "for item_column in ['budget','product_category', 'popularity','runtime', 'vote_count']:\n",
    "    pdata = torch.from_numpy(items[item_column].values.astype('int64'))\n",
    "    g.ndata[item_column] = torch.zeros(g.number_of_nodes(), dtype=torch.int64)\n",
    "    g.ndata[item_column][len(user_ids):len(user_ids) + len(product_ids)] = pdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Item categorical features\n",
    "for col in ['status', 'adult']:\n",
    "    items[col] = items[col].astype('category')\n",
    "    pdata = torch.zeros(g.number_of_nodes(), dtype=torch.int64)\n",
    "    pdata[len(user_ids):len(user_ids) + len(product_ids)] = torch.LongTensor(items[col].cat.codes.values.astype('int64') + 1)\n",
    "    g.ndata[col] = pdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Movie title\n",
    "# nlp = stanfordnlp.Pipeline(use_gpu=False, processors='tokenize,lemma')\n",
    "# vocab = set()\n",
    "# title_words = []\n",
    "# for t in tqdm.tqdm(items['title'].values):\n",
    "#     doc = nlp(t)\n",
    "#     words = set()\n",
    "#     for s in doc.sentences:\n",
    "#         words.update(w.lemma.lower() for w in s.words\n",
    "#                      if not re.fullmatch(r'['+string.punctuation+']+', w.lemma))\n",
    "#     vocab.update(words)\n",
    "#     title_words.append(words)\n",
    "# vocab = list(vocab)\n",
    "\n",
    "# vocab_invmap = {w: i for i, w in enumerate(vocab)}\n",
    "# # bag-of-words\n",
    "# g.ndata['title'] = torch.zeros(g.number_of_nodes(), len(vocab))\n",
    "\n",
    "\n",
    "# for i, tw in enumerate(tqdm.tqdm(title_words)):\n",
    "#     g.ndata['title'][i, [vocab_invmap[w] for w in tw]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>price</th>\n",
       "      <th>product_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c6216.0</td>\n",
       "      <td>i1487</td>\n",
       "      <td>3.0</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c9733.0</td>\n",
       "      <td>i2132</td>\n",
       "      <td>5.0</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c9488.0</td>\n",
       "      <td>i26391</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c4614.0</td>\n",
       "      <td>i39183</td>\n",
       "      <td>4.0</td>\n",
       "      <td>263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c5980.0</td>\n",
       "      <td>i788</td>\n",
       "      <td>4.0</td>\n",
       "      <td>710</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  customer_id item_id  price  product_count\n",
       "0     c6216.0   i1487    3.0             63\n",
       "1     c9733.0   i2132    5.0            103\n",
       "2     c9488.0  i26391    3.0              2\n",
       "3     c4614.0  i39183    4.0            263\n",
       "4     c5980.0    i788    4.0            710"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings= transactions.drop(columns = [\"product_category\", \"date\"]).drop_duplicates()\n",
    "product_count = ratings['item_id'].value_counts()\n",
    "product_count.name = 'product_count'\n",
    "ratings = ratings.join(product_count, on='item_id')\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_by_time = None\n",
    "from functools import partial\n",
    "\n",
    "def split_user(df, filter_counts=0, timestamp=None):\n",
    "    df_new = df.copy()\n",
    "    df_new['prob'] = -1\n",
    "    df_new_sub = (df_new['product_count'] >= filter_counts).to_numpy().nonzero()[0]\n",
    "    prob = np.linspace(0, 1, df_new_sub.shape[0], endpoint=False)\n",
    "    np.random.shuffle(prob)\n",
    "    df_new['prob'].iloc[df_new_sub] = prob\n",
    "    \n",
    "    return df_new\n",
    "\n",
    "def data_split(ratings):\n",
    "    ratings = ratings.groupby('customer_id', group_keys=False).apply(\n",
    "            partial(split_user, filter_counts=5, timestamp=split_by_time))\n",
    "    ratings['train'] = ratings['prob'] <= 0.8\n",
    "    ratings['valid'] = (ratings['prob'] > 0.8) & (ratings['prob'] <= 0.9)\n",
    "    ratings['test'] = ratings['prob'] > 0.9\n",
    "    ratings.drop(['prob'], axis=1, inplace=True)\n",
    "    return ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>price</th>\n",
       "      <th>product_count</th>\n",
       "      <th>train</th>\n",
       "      <th>valid</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38553</th>\n",
       "      <td>c1.0</td>\n",
       "      <td>i4226</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1303</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18957</th>\n",
       "      <td>c1.0</td>\n",
       "      <td>i54503</td>\n",
       "      <td>3.5</td>\n",
       "      <td>352</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32030</th>\n",
       "      <td>c1.0</td>\n",
       "      <td>i110</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2104</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7086</th>\n",
       "      <td>c1.0</td>\n",
       "      <td>i858</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1853</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4817</th>\n",
       "      <td>c1.0</td>\n",
       "      <td>i2959</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1942</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      customer_id item_id  price  product_count  train  valid   test\n",
       "38553        c1.0   i4226    4.0           1303  False   True  False\n",
       "18957        c1.0  i54503    3.5            352   True  False  False\n",
       "32030        c1.0    i110    1.0           2104   True  False  False\n",
       "7086         c1.0    i858    5.0           1853   True  False  False\n",
       "4817         c1.0   i2959    4.0           1942   True  False  False"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_ = data_split(ratings)\n",
    "ratings_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>price</th>\n",
       "      <th>product_count</th>\n",
       "      <th>train</th>\n",
       "      <th>valid</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c1.0</td>\n",
       "      <td>i4226</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1303</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c1.0</td>\n",
       "      <td>i54503</td>\n",
       "      <td>3.5</td>\n",
       "      <td>352</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c1.0</td>\n",
       "      <td>i110</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2104</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c1.0</td>\n",
       "      <td>i858</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1853</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c1.0</td>\n",
       "      <td>i2959</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1942</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  customer_id item_id  price  product_count  train  valid   test\n",
       "0        c1.0   i4226    4.0           1303  False   True  False\n",
       "1        c1.0  i54503    3.5            352   True  False  False\n",
       "2        c1.0    i110    1.0           2104   True  False  False\n",
       "3        c1.0    i858    5.0           1853   True  False  False\n",
       "4        c1.0   i2959    4.0           1942   True  False  False"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_.reset_index(drop = True, inplace = True)\n",
    "ratings_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use ratings df to get lists of source-dest nodes \n",
    "rating_user_vertices = [user_ids_invmap[id_] for id_ in ratings_['customer_id'].values]\n",
    "rating_product_vertices = [product_ids_invmap[id_] + len(user_ids)\n",
    "                         for id_ in ratings_['item_id'].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Partial, edges added \n",
    "g.add_edges(\n",
    "        rating_user_vertices,\n",
    "        rating_product_vertices,\n",
    "        data={'inv': torch.ones(ratings_.shape[0], dtype=torch.uint8),\n",
    "            'rating': torch.FloatTensor(ratings_['price'])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_mask():\n",
    "        valid_tensor = torch.from_numpy(ratings_['valid'].values.astype('uint8'))\n",
    "        test_tensor = torch.from_numpy(ratings_['test'].values.astype('uint8'))\n",
    "        train_tensor = torch.from_numpy(ratings_['train'].values.astype('uint8'))\n",
    "        edge_data = {\n",
    "                'valid': valid_tensor,\n",
    "                'test': test_tensor,\n",
    "                'train': train_tensor,\n",
    "                }\n",
    "\n",
    "        g.edges[rating_user_vertices, rating_product_vertices].data.update(edge_data)\n",
    "        \n",
    "# Generate the list of products for each user in training/validation/test set.\n",
    "def generate_candidates():\n",
    "    p_train = []\n",
    "    p_valid = []\n",
    "    p_test = []\n",
    "    for uid in tqdm.tqdm(user_ids):\n",
    "        user_ratings = ratings_[ratings_['customer_id'] == uid]\n",
    "        p_train.append(np.array(\n",
    "            [product_ids_invmap[i] for i in user_ratings[user_ratings['train']]['item_id'].values]))\n",
    "        p_valid.append(np.array(\n",
    "            [product_ids_invmap[i] for i in user_ratings[user_ratings['valid']]['item_id'].values]))\n",
    "        p_test.append(np.array(\n",
    "            [product_ids_invmap[i] for i in user_ratings[user_ratings['test']]['item_id'].values]))\n",
    "        \n",
    "    return p_train, p_valid, p_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 10363/10363 [09:57<00:00, 17.34it/s]\n"
     ]
    }
   ],
   "source": [
    "generate_mask()\n",
    "\n",
    "p_train, p_valid, p_test = generate_candidates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mix_embeddings(ndata, emb, proj):\n",
    "    \"\"\"Adds external (categorical and numeric) features into node representation G.ndata['h']\"\"\"\n",
    "    extra_repr = []\n",
    "    for key, value in ndata.items():\n",
    "        if (value.dtype == torch.int64) and key in emb:\n",
    "            result = emb[key](value)\n",
    "            if result.dim() == 3:    # bag of words: the result would be a (n_nodes x seq_len x feature_size) tensor\n",
    "                result = result.mean(1)\n",
    "            extra_repr.append(result)\n",
    "        elif (value.dtype == torch.float32) and key in proj:\n",
    "            result = proj[key](value)\n",
    "            extra_repr.append(result)\n",
    "    ndata['h'] = ndata['h'] + torch.stack(extra_repr, 0).sum(0)\n",
    "    \n",
    "def init_weight(param, initializer, nonlinearity):\n",
    "    initializer = getattr(nn.init, initializer)\n",
    "    if nonlinearity is not None:\n",
    "        initializer(param)\n",
    "    else:\n",
    "        initializer(param, nn.init.calculate_gain(nonlinearity))\n",
    "        \n",
    "def init_bias(param):\n",
    "    nn.init.constant_(param, 0)\n",
    "\n",
    "class GraphSageConvWithSampling(nn.Module):\n",
    "    def __init__(self, feature_size):\n",
    "        super(GraphSageConvWithSampling, self).__init__()\n",
    "\n",
    "        self.feature_size = feature_size\n",
    "        self.W = nn.Linear(feature_size * 2, feature_size)\n",
    "        init_weight(self.W.weight, 'xavier_uniform_', 'leaky_relu')\n",
    "        init_bias(self.W.bias)\n",
    "\n",
    "    def forward(self, nodes):\n",
    "        h_agg = nodes.data['h_agg']\n",
    "        h = nodes.data['h']\n",
    "        w = nodes.data['w'][:, None]\n",
    "        h_agg = (h_agg-h)/(w-1).clamp(min=1)    # HACK 1\n",
    "        h_concat = torch.cat([h, h_agg], 1)\n",
    "        h_new = F.leaky_relu(self.W(h_concat))\n",
    "        return {'h': h_new / h_new.norm(dim=1, keepdim=True).clamp(min=1e-6)}\n",
    "    \n",
    "class GraphSageWithSampling(nn.Module):\n",
    "    def __init__(self, feature_size, n_layers, G):\n",
    "        super(GraphSageWithSampling, self).__init__()\n",
    "        \n",
    "        self.feature_size = feature_size\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        self.convs = nn.ModuleList([GraphSageConvWithSampling(feature_size) for _ in range(n_layers)])\n",
    "        \n",
    "        self.emb = nn.ModuleDict()\n",
    "        self.proj = nn.ModuleDict()\n",
    "\n",
    "        for key, scheme in G.node_attr_schemes().items():\n",
    "            if scheme.dtype == torch.int64:\n",
    "                n_items = G.ndata[key].max().item()\n",
    "                self.emb[key] = nn.Embedding(\n",
    "                        n_items + 1,\n",
    "                        self.feature_size,\n",
    "                        padding_idx=0)\n",
    "                nn.init.normal_(self.emb[key].weight, 1 / self.feature_size)\n",
    "            elif scheme.dtype == torch.float32:\n",
    "                w = nn.Linear(scheme.shape[0], self.feature_size)\n",
    "                init_weight(w.weight, 'xavier_uniform_', 'leaky_relu')\n",
    "                init_bias(w.bias)\n",
    "                self.proj[key] = nn.Sequential(w, nn.LeakyReLU())\n",
    "                \n",
    "        self.G = G\n",
    "        \n",
    "        self.node_emb = nn.Embedding(G.number_of_nodes() + 1, feature_size)\n",
    "        nn.init.normal_(self.node_emb.weight, std=1 / self.feature_size)\n",
    "\n",
    "    msg = [FN.copy_src('h', 'h'),\n",
    "           FN.copy_src('one', 'one')]\n",
    "    red = [FN.sum('h', 'h_agg'), FN.sum('one', 'w')]\n",
    "\n",
    "    def forward(self, nf):\n",
    "        '''\n",
    "        nf: NodeFlow.\n",
    "        '''\n",
    "        nf.copy_from_parent(edge_embed_names=None)\n",
    "        for i in range(nf.num_layers):\n",
    "            nf.layers[i].data['h'] = self.node_emb(nf.layer_parent_nid(i) + 1)\n",
    "            nf.layers[i].data['one'] = torch.ones(nf.layer_size(i))\n",
    "            mix_embeddings(nf.layers[i].data, model.gcn.emb, model.gcn.proj)\n",
    "        if self.n_layers == 0:\n",
    "            return nf.layers[i].data['h']\n",
    "        for i in range(self.n_layers):\n",
    "            nf.block_compute(i, self.msg, self.red, self.convs[i])\n",
    "\n",
    "        result = nf.layers[self.n_layers].data['h']\n",
    "        assert (result != result).sum() == 0\n",
    "        return result\n",
    "    \n",
    "class GraphSAGERecommender(nn.Module):\n",
    "    def __init__(self, gcn):\n",
    "        super(GraphSAGERecommender, self).__init__()\n",
    "        \n",
    "        self.gcn = gcn\n",
    "        self.node_biases = nn.Parameter(torch.zeros(gcn.G.number_of_nodes()+1))\n",
    "        \n",
    "    def forward(self, nf, src, dst):\n",
    "        h_output = self.gcn(nf)\n",
    "        h_src = h_output[nodeflow.map_from_parent_nid(-1, src, True)]\n",
    "        h_dst = h_output[nodeflow.map_from_parent_nid(-1, dst, True)]\n",
    "        score = (h_src * h_dst).sum(1) + self.node_biases[src+1] + self.node_biases[dst+1]\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the subgraph of all \"training\" edges\n",
    "g_train = g.edge_subgraph(g.filter_edges(lambda edges: edges.data['train']), True)\n",
    "g_train_ = g_train\n",
    "# g_train.copy_from_parent()\n",
    "# g_train.readonly()\n",
    "\n",
    "#Obtain edge id's for valid and test data\n",
    "eid_valid = g.filter_edges(lambda edges: edges.data['valid'])\n",
    "eid_test = g.filter_edges(lambda edges: edges.data['test'])\n",
    "\n",
    "#Storing source and dest node ids for train, valid, test edges\n",
    "src_valid, dst_valid = g.find_edges(eid_valid)\n",
    "src_test, dst_test = g.find_edges(eid_test)\n",
    "src, dst = g_train.all_edges()\n",
    "\n",
    "#storing ratings for train, valid, test edges\n",
    "rating = g_train.edata['rating']\n",
    "rating_valid = g.edges[eid_valid].data['rating']\n",
    "rating_test = g.edges[eid_test].data['rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "eid_train = g_train.filter_edges(lambda edges: edges.data['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "G=g\n",
    "graph = g\n",
    "batch_size = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_eid_dict = eid_train\n",
    "\n",
    "sampler = dgl.dataloading.MultiLayerNeighborSampler([5, 10, 15])\n",
    "\n",
    "dataloader = dgl.dataloading.EdgeDataLoader(\n",
    "    g_train, train_eid_dict, sampler,\n",
    "    negative_sampler=dgl.dataloading.negative_sampler.Uniform(5),\n",
    "    batch_size=1024,\n",
    "    shuffle=True,\n",
    "    drop_last=False,\n",
    "    num_workers=4)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build model \n",
    "model = GraphSAGERecommender(GraphSageWithSampling(10, 1, g_train))\n",
    "opt = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-9)\n",
    "\n",
    "batch_size = 1024\n",
    "n_users = len(customers['customer_id'].to_list())\n",
    "n_products = len(items['item_id'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = model.cuda()\n",
    "for input_nodes, positive_graph, negative_graph, blocks in dataloader:\n",
    "    blocks = [b.to(torch.device('cuda')) for b in blocks]\n",
    "    positive_graph = positive_graph.to(torch.device('cuda'))\n",
    "    negative_graph = negative_graph.to(torch.device('cuda'))\n",
    "    input_features = blocks[0].srcdata['features']\n",
    "    score = model.forward(nodeflow, s, d)\n",
    "    loss = ((score - r) ** 2).mean()\n",
    "    opt.zero_grad()\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    \n",
    "    pos_score, neg_score = model(positive_graph, blocks, input_features)\n",
    "    loss = compute_loss(pos_score, neg_score)\n",
    "    opt.zero_grad()\n",
    "    loss.backward()\n",
    "    opt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphSAGERecommender(\n",
       "  (gcn): GraphSageWithSampling(\n",
       "    (convs): ModuleList(\n",
       "      (0): GraphSageConvWithSampling(\n",
       "        (W): Linear(in_features=20, out_features=10, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (emb): ModuleDict(\n",
       "      (alive): Embedding(2, 10, padding_idx=0)\n",
       "      (budget): Embedding(380000001, 10, padding_idx=0)\n",
       "      (product_category): Embedding(11, 10, padding_idx=0)\n",
       "      (popularity): Embedding(141, 10, padding_idx=0)\n",
       "      (runtime): Embedding(481, 10, padding_idx=0)\n",
       "      (vote_count): Embedding(12270, 10, padding_idx=0)\n",
       "      (status): Embedding(5, 10, padding_idx=0)\n",
       "      (adult): Embedding(3, 10, padding_idx=0)\n",
       "      (_ID): Embedding(15162, 10, padding_idx=0)\n",
       "    )\n",
       "    (proj): ModuleDict()\n",
       "    (node_emb): Embedding(15163, 10)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'features'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-09ee5259592f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0minput_nodes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpositive_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnegative_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblocks\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrcdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'features'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrcdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'features'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pai_dglv5_item\\lib\\site-packages\\dgl\\view.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m     64\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_n_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ntid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nodes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pai_dglv5_item\\lib\\site-packages\\dgl\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    384\u001b[0m             \u001b[0mColumn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    385\u001b[0m         \"\"\"\n\u001b[1;32m--> 386\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_columns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    387\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    388\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'features'"
     ]
    }
   ],
   "source": [
    "for input_nodes, positive_graph, negative_graph, blocks in dataloader:\n",
    "    print(blocks[0].srcdata['features'])\n",
    "    print(blocks[1].srcdata['features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7424, 4645, 2099,  ..., 3799, 2775, 4597])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(num_nodes=5362, num_edges=1024,\n",
       "      ndata_schemes={'alive': Scheme(shape=(), dtype=torch.int64), 'budget': Scheme(shape=(), dtype=torch.int64), 'product_category': Scheme(shape=(), dtype=torch.int64), 'popularity': Scheme(shape=(), dtype=torch.int64), 'runtime': Scheme(shape=(), dtype=torch.int64), 'vote_count': Scheme(shape=(), dtype=torch.int64), 'status': Scheme(shape=(), dtype=torch.int64), 'adult': Scheme(shape=(), dtype=torch.int64), '_ID': Scheme(shape=(), dtype=torch.int64)}\n",
       "      edata_schemes={'inv': Scheme(shape=(), dtype=torch.uint8), 'rating': Scheme(shape=(), dtype=torch.float32), 'valid': Scheme(shape=(), dtype=torch.uint8), 'test': Scheme(shape=(), dtype=torch.uint8), 'train': Scheme(shape=(), dtype=torch.uint8), '_ID': Scheme(shape=(), dtype=torch.int64)})"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(num_nodes=5362, num_edges=5120,\n",
       "      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}\n",
       "      edata_schemes={})"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<dgl.dataloading.neighbor.MultiLayerNeighborSampler at 0x2bf38ce8188>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StochasticTwoLayerRGCN(nn.Module):\n",
    "    def __init__(self, in_feat, hidden_feat, out_feat):\n",
    "        super().__init__()\n",
    "        self.conv1 = dglnn.HeteroGraphConv({\n",
    "                rel : dglnn.GraphConv(in_feat, hidden_feat, norm='right')\n",
    "                for rel in rel_names\n",
    "            })\n",
    "        self.conv2 = dglnn.HeteroGraphConv({\n",
    "                rel : dglnn.GraphConv(hidden_feat, out_feat, norm='right')\n",
    "                for rel in rel_names\n",
    "            })\n",
    "\n",
    "    def forward(self, blocks, x):\n",
    "        x = self.conv1(blocks[0], x)\n",
    "        x = self.conv2(blocks[1], x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScorePredictor(nn.Module):\n",
    "    def forward(self, edge_subgraph, x):\n",
    "        with edge_subgraph.local_scope():\n",
    "            edge_subgraph.ndata['x'] = x\n",
    "            for etype in edge_subgraph.canonical_etypes:\n",
    "                edge_subgraph.apply_edges(\n",
    "                    dgl.function.u_dot_v('x', 'x', 'score'), etype=etype)\n",
    "            return edge_subgraph.edata['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features, out_features):\n",
    "        super().__init__()\n",
    "        self.\n",
    "        self.gcn = StochasticTwoLayerRGCN(\n",
    "            in_features, hidden_features, out_features)\n",
    "        self.predictor = ScorePredictor(\n",
    "            edge_subgraph, x)\n",
    "\n",
    "    def forward(self, positive_graph, negative_graph, blocks, x):\n",
    "        x = self.gcn(blocks, x)\n",
    "        pos_score = self.predictor(positive_graph, x)\n",
    "        neg_score = self.predictor(negative_graph, x)\n",
    "        return pos_score, neg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alive': Scheme(shape=(), dtype=torch.int64),\n",
       " 'budget': Scheme(shape=(), dtype=torch.int64),\n",
       " 'product_category': Scheme(shape=(), dtype=torch.int64),\n",
       " 'popularity': Scheme(shape=(), dtype=torch.int64),\n",
       " 'runtime': Scheme(shape=(), dtype=torch.int64),\n",
       " 'vote_count': Scheme(shape=(), dtype=torch.int64),\n",
       " 'status': Scheme(shape=(), dtype=torch.int64),\n",
       " 'adult': Scheme(shape=(), dtype=torch.int64)}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.node_attr_schemes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-5aa97b4f005b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mopt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model = model.cuda()\n",
    "opt = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alive': tensor([1, 1, 1,  ..., 1, 1, 1]), 'budget': tensor([0, 0, 0,  ..., 0, 0, 0]), 'product_category': tensor([0, 0, 0,  ..., 0, 0, 0]), 'popularity': tensor([0, 0, 0,  ..., 0, 0, 0]), 'runtime': tensor([0, 0, 0,  ..., 0, 0, 0]), 'vote_count': tensor([0, 0, 0,  ..., 0, 0, 0]), 'status': tensor([0, 0, 0,  ..., 0, 0, 0]), 'adult': tensor([0, 0, 0,  ..., 0, 0, 0]), '_ID': tensor([  572,    59, 10341,  ...,  5385,  5787,  2031])}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blocks[0].srcdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'features'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-09ee5259592f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0minput_nodes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpositive_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnegative_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblocks\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrcdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'features'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrcdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'features'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pai_dglv5_item\\lib\\site-packages\\dgl\\view.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m     64\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_n_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ntid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nodes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pai_dglv5_item\\lib\\site-packages\\dgl\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    384\u001b[0m             \u001b[0mColumn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    385\u001b[0m         \"\"\"\n\u001b[1;32m--> 386\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_columns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    387\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    388\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'features'"
     ]
    }
   ],
   "source": [
    "for input_nodes, positive_graph, negative_graph, blocks in dataloader:\n",
    "    print(blocks[0].srcdata['features'])\n",
    "    print(blocks[1].srcdata['features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alive': tensor([1, 1, 1,  ..., 1, 1, 1]), 'budget': tensor([0, 0, 0,  ..., 0, 0, 0]), 'product_category': tensor([0, 0, 0,  ..., 0, 0, 0]), 'popularity': tensor([0, 0, 0,  ..., 0, 0, 0]), 'runtime': tensor([0, 0, 0,  ..., 0, 0, 0]), 'vote_count': tensor([0, 0, 0,  ..., 0, 0, 0]), 'status': tensor([0, 0, 0,  ..., 0, 0, 0]), 'adult': tensor([0, 0, 0,  ..., 0, 0, 0]), '_ID': tensor([  572,    59, 10341,  ...,  5385,  5787,  2031])}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blocks[0].srcdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'in_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-63-7d09fd3d5e11>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0min_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mopt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0minput_nodes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpositive_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnegative_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblocks\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'in_features' is not defined"
     ]
    }
   ],
   "source": [
    "# model = Model(in_features, hidden_features, out_features)\n",
    "# model = model.cuda()\n",
    "# opt = torch.optim.Adam(model.parameters())\n",
    "\n",
    "for input_nodes, positive_graph, negative_graph, blocks in dataloader:\n",
    "    model = Model(in_features, hidden_features, out_features)\n",
    "    model = model.cuda()\n",
    "    opt = torch.optim.Adam(model.parameters())\n",
    "    blocks = [b.to(torch.device('cuda')) for b in blocks]\n",
    "    positive_graph = positive_graph.to(torch.device('cuda'))\n",
    "    negative_graph = negative_graph.to(torch.device('cuda'))\n",
    "    input_features = blocks[0].srcdata['features']\n",
    "    pos_score, neg_score = model(positive_graph, blocks, input_features)\n",
    "    loss = compute_loss(pos_score, neg_score)\n",
    "    opt.zero_grad()\n",
    "    loss.backward()\n",
    "    opt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build model \n",
    "model = GraphSAGERecommender(GraphSageWithSampling(10, 1, g_train))\n",
    "opt = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-9)\n",
    "\n",
    "batch_size = 1024\n",
    "n_users = len(customers['customer_id'].to_list())\n",
    "n_products = len(items['item_id'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'in_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-65-606fa198aee3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStochasticTwoLayerRGCN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0min_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mopt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0minput_nodes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblocks\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'in_features' is not defined"
     ]
    }
   ],
   "source": [
    "model_ = StochasticTwoLayerRGCN(in_features, hidden_features, out_features)\n",
    "model = model.cuda()\n",
    "opt = torch.optim.Adam(model.parameters())\n",
    "\n",
    "for input_nodes, blocks in dataloader:\n",
    "    blocks = [b.to(torch.device('cuda')) for b in blocks]\n",
    "    input_features = blocks[0].srcdata     # returns a dict\n",
    "    output_labels = blocks[-1].dstdata     # returns a dict\n",
    "    output_predictions = model(blocks, input_features)\n",
    "    loss = compute_loss(output_labels, output_predictions)\n",
    "    opt.zero_grad()\n",
    "    loss.backward()\n",
    "    opt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define feature size and layers in gNN\n",
    "feature_size = 10\n",
    "n_layers = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Block(num_src_nodes=9093, num_dst_nodes=8871, num_edges=6900), Block(num_src_nodes=8871, num_dst_nodes=8202, num_edges=11999), Block(num_src_nodes=8202, num_dst_nodes=5378, num_edges=16528)]\n"
     ]
    }
   ],
   "source": [
    "input_nodes,a,b, blocks = next(iter(dataloader))\n",
    "print(blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph(num_nodes=5378, num_edges=1024,\n",
      "      ndata_schemes={'alive': Scheme(shape=(), dtype=torch.int64), 'budget': Scheme(shape=(), dtype=torch.int64), 'product_category': Scheme(shape=(), dtype=torch.int64), 'popularity': Scheme(shape=(), dtype=torch.int64), 'runtime': Scheme(shape=(), dtype=torch.int64), 'vote_count': Scheme(shape=(), dtype=torch.int64), 'status': Scheme(shape=(), dtype=torch.int64), 'adult': Scheme(shape=(), dtype=torch.int64), '_ID': Scheme(shape=(), dtype=torch.int64)}\n",
      "      edata_schemes={'inv': Scheme(shape=(), dtype=torch.uint8), 'rating': Scheme(shape=(), dtype=torch.float32), 'valid': Scheme(shape=(), dtype=torch.uint8), 'test': Scheme(shape=(), dtype=torch.uint8), 'train': Scheme(shape=(), dtype=torch.uint8), '_ID': Scheme(shape=(), dtype=torch.int64)})\n"
     ]
    }
   ],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph(num_nodes=5378, num_edges=5120,\n",
      "      ndata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)}\n",
      "      edata_schemes={})\n"
     ]
    }
   ],
   "source": [
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pv23228\\Anaconda3\\envs\\pai_dglv5_item\\lib\\site-packages\\dgl\\base.py:45: DGLWarning: DGLGraph.readonly is deprecated in v0.5.\n",
      "DGLGraph now always supports mutable operations like add_nodes and add_edges.\n",
      "  return warnings.warn(message, category=category, stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "Graph_train = g_train\n",
    "g_train.readonly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build model \n",
    "model = GraphSAGERecommender(GraphSageWithSampling(10, 1, g_train))\n",
    "opt = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-9)\n",
    "\n",
    "batch_size = 1024\n",
    "n_users = len(customers['customer_id'].to_list())\n",
    "n_products = len(items['item_id'].to_list())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_train.readonly(readonly_state=True)\n",
    "g_train.is_readonly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pv23228\\Anaconda3\\envs\\pai_dglv5_item\\lib\\site-packages\\dgl\\base.py:45: DGLWarning: dgl.contrib.sampling.NeighborSampler is deprecated starting from v0.5. Please read our guide<link> for how to use the new sampling APIs.\n",
      "  return warnings.warn(message, category=category, stacklevel=1)\n",
      "C:\\Users\\pv23228\\Anaconda3\\envs\\pai_dglv5_item\\lib\\site-packages\\dgl\\base.py:45: DGLWarning: DGLGraph.is_readonly is deprecated in v0.5.\n",
      "DGLGraph now always supports mutable operations like add_nodes and add_edges.\n",
      "  return warnings.warn(message, category=category, stacklevel=1)\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "NeighborSampler doesn't support mutable graphs. Please turn it into an immutable graph with DGLGraphStale.readonly",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-ab40ac2927d6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0madd_self_loop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[0mnum_workers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m     )\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pai_dglv5_item\\lib\\site-packages\\dgl\\contrib\\sampling\\sampler.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, g, batch_size, expand_factor, num_hops, neighbor_type, transition_prob, seed_nodes, shuffle, num_workers, prefetch, add_self_loop)\u001b[0m\n\u001b[0;32m    318\u001b[0m                     ' Please read our guide<link> for how to use the new sampling APIs.')\n\u001b[0;32m    319\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 320\u001b[1;33m         \u001b[1;32massert\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_readonly\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"NeighborSampler doesn't support mutable graphs. \"\u001b[0m \u001b[1;33m+\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    321\u001b[0m                 \u001b[1;34m\"Please turn it into an immutable graph with DGLGraphStale.readonly\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexpand_factor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIntegral\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'non-int expand_factor not supported'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: NeighborSampler doesn't support mutable graphs. Please turn it into an immutable graph with DGLGraphStale.readonly"
     ]
    }
   ],
   "source": [
    "#Build model \n",
    "# model = GraphSAGERecommender(GraphSageWithSampling(10, 1, g_train))\n",
    "# opt = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-9)\n",
    "\n",
    "batch_size = 512\n",
    "n_users = len(customers['customer_id'].to_list())\n",
    "n_products = len(items['item_id'].to_list())\n",
    "\n",
    "#Running model training for 50 epochs\n",
    "for epoch in range(50):\n",
    "    model.eval()\n",
    "    \n",
    "    # Validation & Test, we precompute GraphSage output for all nodes first.\n",
    "    sampler = dgl.contrib.sampling.NeighborSampler(\n",
    "        g_train,\n",
    "        batch_size,\n",
    "        5,\n",
    "        1,\n",
    "        seed_nodes=torch.arange(g_train.number_of_nodes()),\n",
    "        prefetch=True,\n",
    "        add_self_loop=True,\n",
    "        shuffle=False,\n",
    "        num_workers=4\n",
    "    )\n",
    "\n",
    "    with torch.no_grad():\n",
    "        h = []\n",
    "        for nf in sampler:\n",
    "            #import pdb\n",
    "            #pdb.set_trace()\n",
    "            h.append(model.gcn.forward(nf))\n",
    "        h = torch.cat(h)\n",
    "\n",
    "        # Compute validation RMSE\n",
    "        score = torch.zeros(len(src_valid))\n",
    "        for i in range(0, len(src_valid), batch_size):\n",
    "            s = src_valid[i:i+batch_size]\n",
    "            d = dst_valid[i:i+batch_size]\n",
    "            score[i:i+batch_size] = (h[s] * h[d]).sum(1) + model.node_biases[s + 1] + model.node_biases[d + 1]\n",
    "        valid_rmse = ((score - rating_valid) ** 2).mean().sqrt()\n",
    "\n",
    "        # Compute test RMSE\n",
    "        score = torch.zeros(len(src_test))\n",
    "        for i in range(0, len(src_test), batch_size):\n",
    "            s = src_test[i:i+batch_size]\n",
    "            d = dst_test[i:i+batch_size]\n",
    "            score[i:i+batch_size] = (h[s] * h[d]).sum(1) + model.node_biases[s + 1] + model.node_biases[d + 1]\n",
    "        test_rmse = ((score - rating_test) ** 2).mean().sqrt()\n",
    "        \n",
    "    model.train()\n",
    "    \n",
    "    shuffle_idx = torch.randperm(g_train.number_of_edges())\n",
    "    src_shuffled = src[shuffle_idx]\n",
    "    dst_shuffled = dst[shuffle_idx]\n",
    "    rating_shuffled = rating[shuffle_idx]\n",
    "    src_batches = src_shuffled.split(batch_size)\n",
    "    dst_batches = dst_shuffled.split(batch_size)\n",
    "    rating_batches = rating_shuffled.split(batch_size)\n",
    "\n",
    "    seed_nodes = torch.cat(sum([[s, d] for s, d in zip(src_batches, dst_batches)], []))\n",
    "    \n",
    "    sampler = dgl.contrib.sampling.NeighborSampler(\n",
    "        g_train,               # the graph\n",
    "        batch_size * 2,        # number of nodes to compute at a time, HACK 2\n",
    "        5,                     # number of neighbors for each node\n",
    "        1,                     # number of layers in GCN\n",
    "        seed_nodes=seed_nodes, # list of seed nodes, HACK 2\n",
    "        prefetch=True,         # whether to prefetch the NodeFlows\n",
    "        add_self_loop=True,    # whether to add a self-loop in the NodeFlows, HACK 1\n",
    "        shuffle=False,         # whether to shuffle the seed nodes.  Should be False here.\n",
    "        num_workers=4,\n",
    "    )\n",
    "\n",
    "    #Training\n",
    "    for s, d, r, nodeflow in zip(src_batches, dst_batches, rating_batches, sampler):\n",
    "        score = model.forward(nodeflow, s, d)\n",
    "        loss = ((score - r) ** 2).mean()\n",
    "        \n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "    print('Training loss:', loss.item(), 'Validation RMSE:', valid_rmse.item(), 'Test RMSE:', test_rmse.item())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " import dgl\n",
    ">>> import scipy as sp\n",
    ">>> m = sp.sparse.random(100, 100, density=0.1, format='csr')\n",
    ">>> g= dgl.DGLGraph(m, readonly=True)\n",
    ">>> g.number_of_nodes()\n",
    "100\n",
    ">>> g.number_of_edges()\n",
    "1000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphSAGERecommender(\n",
       "  (gcn): GraphSageWithSampling(\n",
       "    (convs): ModuleList(\n",
       "      (0): GraphSageConvWithSampling(\n",
       "        (W): Linear(in_features=20, out_features=10, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (emb): ModuleDict(\n",
       "      (alive): Embedding(2, 10, padding_idx=0)\n",
       "      (budget): Embedding(380000001, 10, padding_idx=0)\n",
       "      (product_category): Embedding(11, 10, padding_idx=0)\n",
       "      (popularity): Embedding(141, 10, padding_idx=0)\n",
       "      (runtime): Embedding(481, 10, padding_idx=0)\n",
       "      (vote_count): Embedding(12270, 10, padding_idx=0)\n",
       "      (status): Embedding(5, 10, padding_idx=0)\n",
       "      (adult): Embedding(3, 10, padding_idx=0)\n",
       "      (_ID): Embedding(15162, 10, padding_idx=0)\n",
       "    )\n",
       "    (proj): ModuleDict(\n",
       "      (title): Sequential(\n",
       "        (0): Linear(in_features=4854, out_features=10, bias=True)\n",
       "        (1): LeakyReLU(negative_slope=0.01)\n",
       "      )\n",
       "    )\n",
       "    (node_emb): Embedding(15163, 10)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
